% настройки в preamble.inc
\include{preamble.inc}
\usepackage{enumitem}
\usepackage{indentfirst}
\usepackage{gensymb}
\usepackage{enumerate}
\usepackage{float}


\graphicspath{{images/}}
\begin{document}

\setcounter{page}{3}

% СОДЕРЖАНИЕ 
\clearpage
\tableofcontents

% ВВЕДЕНИЕ
\clearpage
\section*{Введение}
\addcontentsline{toc}{section}{Введение}
Задача по сбору и анализу трафика может возникнуть в различных ситуациях. Например, при наблюдении за поведением пользователей во внутренней сети, попытке отследить вредоносное программное обеспечение, обращающееся к внешнему сервису, или при контроле квоты использования интернета. Большой объем данных, проходящих через сетевые узлы, накладывает некоторые ограничения на инструменты, используемые при решении поставленной задачи.
	\\ \indent Целью данной работы является реализация программного комплекса для сбора, хранения и анализа информации о трафике, проходящего через некоторый сетевой узел.

Для достижения поставленной цели необходимо решить следующие задачи:
\begin{itemize}
	\item проанализировать предметную область;
	\item спроектировать программный комплекс;
	\item реализовать спроектированную систему.
\end{itemize}

% АНАЛИТИЧЕСКАЯ ЧАСТЬ
\clearpage
\section{Аналитический раздел}
В данном разделе будет поставлена задача, рассмотрены требования к системе и проведен анализ существующих решений.

\subsection{Постановка задачи}
Необходимо разработать программный комплекс, предоставляющий возможность собирать, хранить и просматривать информацию о трафике, проходящем через сетевой узел.

Предусмотреть наличие нескольких ролей пользователей с разным уровнем привилегий:
\begin{itemize}
	\item пользователь "Гость"\ с возможностью просмотра базовых таблиц;
	\item пользователь "Аналитик"\  с возможностью запуска сложных запросов и наличием тех же прав, что и у "Гость";
	\item пользователь "Администратор"\  с возможностью управления аккаунтами пользователей и наличием тех же прав, что и у "Аналитик".
\end{itemize}

\subsection{Требования к системе}
\begin{itemize}
	\item система должна обладать возможностью масштабирования на несколько сетевых узлов, кластеров хранения данных;
	\item необходимо обеспечить долгосрочное хранение больших объемов данных (трафик за несколько лет) с сохранением возможности поиска предыдущих записей
		за приемлемое время;
	\item предусмотреть возможность непрерывной работы подсистемы сбора данных в течении длительного времени.
\end{itemize}

\subsection{ Общие сведения }
Информация о трафике обычно представляется с помощью NetFlow протокола\cite{netflow}. Существуют различные версии протокола, но принцип работы у всех них один. Для сбора данных с помощью NetFlow используют следующие компоненты:
\begin{itemize}
	\item сенсор;
	\item коллектор;
	\item анализатор.
\end{itemize}
\indent \indent Сенсор служит для сбора статистики о проходящем через него трафике. Данные, собранные сенсором отправляются в коннектор, который агрегирует данные с нескольких сенсоров и записывает их в хранилище. Анализатор предоставляет возможность работы с данными. Схема архитектуры NetFlow представлена на рисунке \ref{netflow}.
\begin{figure}[H]
	\centering
	\includegraphics[scale=0.5]{netflow.png}
	\caption{Архитектура NetFlow.}
	\label{netflow}
\end{figure}

\subsection{ Анализ существующих решений}
Исходя из изложенных выше сведений можно выделить два направления поиска возможного решения:
\begin{itemize}
	\item приложение, реализующее в себе все компоненты архитектуры NetFlow;
	\item система, использующая отдельные компоненты вместе.
\end{itemize}

\subsubsection{ Приложение }
По первому направлению сравнения можно выделить два самых видных решения:
\begin{itemize}
	\item Wireshark;
	\item tcpdump.
\end{itemize}

\subsubsubsection{Wireshark}
Бесплатный, мультиплатформенный (работает на Windows, macOS и семействе Linux) анализатор трафика с открытым исходным кодом, предоставляющий возможность быстро проанализировать трафик сети\cite{wireshark}. Есть возможность фильтровать и сортировать трафик. Имеет интуитивно понятный и информативный интерфейс. Однако позволяет работать только с локальными интерфейсами, а записанные данные сохраняет в простой файл, что делает его неприменимым для долгосрочного сбора данных и не дает возможности масштабирования.
\subsubsubsection{tcpdump}
Бесплатный анализатор трафика\cite{tcpdump}. Работает на Linux, но есть несколько портов для Windows. Предоставляет базовую функциональность через консольный интерфейс. Минусы такие же как и у Wireshark - отсутствие возможности масштабирования и работа только с локальными интерфейсами.

Как видно, готовые программы анализа информации о трафике имеют общие недостатки, не позволяющие использовать их для решения поставленной задачи.
\subsubsection{ Система }
По второму направлению сравнения выделить готовых систем не удалось, но можно выделить некоторые популярные решения отдельных модулей.

Утилита fprobe широко применяется в качестве сенсора, так как он прост в использовании. \\
	\indent Стек ELK(Elasticksearch, Logstash, Kibana) применяется в качестве коллектора и анализатора. Logstash позволяет не терять данные в случае временного выхода из строя Elasticksearch, а Kibana визуализирует данные, выступая в роли анализатора. Стоит заметить, что БД Elasticksearch это документо-ориентированная NoSQL база данных, что делает её очень эффективной при работе с большими данными\cite{elastic}. \\
	\indent Другая NoSQL база данных Clickhouse является  \\ столбцово-ориентированной и её производительность выше чем у Elasticksearch\cite{clickhouse-elastic}. \\
	\indent Так же в качестве Коллектора может использоваться Kafka, предоставляющий ту же функциональность что и Logstash, но имеющий более гибкий инструментарий для масштабирования. \\
	\indent У Clickhouse есть нативная интеграция c Kafka, что, вкупе с преимуществами этих сервисов по отдельности и требованиями к системе, делает выбор этой связки оправданым для решения поставленной задачи\cite{clickhouse-kafka}.

\subsection{Вывод}
В данном разделе была поставлена задача, рассмотрены требования к системе, проанализированы существующие решения.


%КОНСТРУКТОРСКИЙ РАЗДЕЛ
\clearpage
\section{Конструкторский раздел}
В данном разделе будут спроектированы база данных и приложение.


\subsection{Сценарии использования}
Необходимо формализовать требуемую функциональность. 
\subsubsection{Гость}
У пользователя с ролью "Гость"\ есть только самые базовые права - права на просмотр существующие данные, без возможности их как-либо менять или делать сложные запросы.
Разрешаемые действия:
\begin{itemize}
	\item[1)] просмотр всех источников;
	\item[2)] просмотр всех типов источников;
	\item[3)] просмотр всех владельцев источников;
	\item[4)] просмотр всех точек назначения;
	\item[5)] просмотр всех типов точек назначений;
	\item[6)] просмотр потока данных за последние n минут.
\end{itemize}

\subsubsection{Аналитик}
Функциональность, предоставляемая аналитику расширяет возможности гостя:
\begin{itemize}
	\item[1)] просмотр потока определенного типа;
	\item[2)] просмотр потока из определенного интервала;
	\item[3)] получение суммы трафика от источников к определенным точкам назначения.
\end{itemize}
\subsubsection{Администратор}
Администратор, помимо предоставляемого аналитику функционала, может управлять аккаунтами пользователей:
\begin{itemize}
	\item[1)] просмотреть всех пользователей;
	\item[2)] удалить пользователя;
	\item[3)] создать пользователя;
	\item[4)] выдать права пользователю;
	\item[5)] забрать права у пользователя.
\end{itemize}

\subsection{Ролевая модель}
На уровне базы данных введены следующие роли:
\begin{itemize}
	\item[1)] guest;
	\item[2)] analyst;
	\item[3)] admin.
\end{itemize}
\indent \indent Права приведенных ролей совпадают с возможностями пользователей этой роли.


\subsection{Проектирование базы данных}
Необходимо выделить и описать сущности и ролевую модель.
\subsubsection{Формализация сущностей системы}
На рисунке \ref{ER} представлена ER-диаграмма системы.
\begin{figure}[H]
	\centering
	\includegraphics[scale=0.18]{ER.png}
	\caption{ER-диаграмма системы.}
	\label{ER}
\end{figure}
Выделенные сущности:
\begin{itemize}
	\item[1)] Пользователь - пользователь системы;
	\item[2)] Администратор, Гость, Аналитик - роли;
	\item[3)] Поток - поток данных;
	\item[4)] Источник - источник потока;
	\item[5)] Тип источника - тип источника;
	\item[6)] Владелец источника - так как предполагается, что мы находимся во внутренней сети, у источника есть известное нам расположение и владелец;
	\item[7)] Назначение - место назначение потока данных.
	\item[8)] Тип назначения - тип точки назначения.
\end{itemize}

\subsubsection{Функции и триггеры}
Для того, чтобы автоматически сортировать потоки трафика, необходимо создать триггер на добавление в таблицу потоков. Функции же нужны для аналитических запросов.

\subsection{Проектирование приложения}
Приложение анализатор NetFlow спроектировано по архитектурному паттерну MVC.
Были выделены три компонента:
\begin{enumerate}
	\item доступа к данным;
	\item бизнес-логики;
	\item интерфейса.
\end{enumerate}
\indent \indent Компонент доступа к данным предоставляет интерфейс для взаимодействия с базой данных. В компоненте бизнес-логики содержатся контроллеры, использующиеся в компоненте интерфейса.
\subsection{Вывод}
В данном разделе были рассмотрены сценарии использования, спроектирована база данных и спроектировано приложение.

\newpage
%ТЕХНОЛОГИЧЕСКИЙ РАЗДЕЛ
\section{Технологический раздел}
В данном разделе будут выбраны средства реализации поставленной задачи, создана база данных и ролевая модель, разработаны компоненты и описан порядок работы.
\subsection{Средства реализации поставленной задачи}
В качестве языка программирования был выбран язык C\#, так как он поддерживает парадигму ООП, имеет большой набор библиотек, легкий в использовании конструктор интерфейса для WinForms\cite{sharp}. \\
\indent В качестве среды разработки была выбрана "Microsoft Visual Studio 2019"\cite{vs}, поскольку она имеет много полезных возможностей при написании кода на C\#\cite{vs}. \\
\indent В качестве сенсора будет использоваться fprobe так как он прост в использовании. В качестве коллектора будет применяться связка Kafka + Clickhouse из-за преимуществ, описанных в аналитической части. В качестве коллектора для Kafka будет использован Goflow, преобразующий все реализации протокола Netflow к формату protobuf, который будет использоваться в дальнейшем. \\
\indent В качестве инструмента развертывания был выбран Docker, так как он позволяет быстро и без установки сторонних модулей развернуть приложение на новой машине.
\subsection{Создание базы данных}
Специфика Clickhouse наложила некоторые ограничения. Clickhouse не поддерживает PrimaryKey и ForeignKey, не поддерживает уникальность значений в таблице, отсутствует поддержка транзакций и другие особенности\cite{clickhouse}. В связи с этим нельзя сказать, что одна таблица ссылается на другую и нельзя построить диаграмму БД. На рисунке \ref{img:DB} представлены сущности БД. В приложении А приведен листинг создания БД. \\
\begin{figure}[H]
	\centering
	\includegraphics[scale=0.55]{images/bd.png}
	\caption{Диаграмма БД.}
	\label{img:DB}
\end{figure}
В данном случае таблица flows напрямую берет данные из Kafka, но не хранит в себе данные предыдущего запроса к Kafka, а только последнего. Таблица же flows\_raw, дублируя flows, не удаляет старые данные при получении новых. Синхронизировать запись в flows\_raw при добавлении во flows помогает flows\_raw\_view - материализованное представление, ещё одна особенность Clickhouse. В Clickhouse отсутствуют триггеры и функции, определяемые пользователем, но вместо этого существуют материализованные представления, которые работают схожим образом с триггером добавления.
\subsection{Разработка компонентов}
При разработке приложения были встречены трудности, так же обусловленные выбором Clickhouse.
\subsubsection{Компонент доступа к данным}
В C\# есть фрэймворк EntityFramework и его модули, предоставляющие ORM для многих популярных баз данных, тем самым существенно упрощая процесс разработки. Но для Clickhouse нет готовой ORM, поэтому компонент доступа данным использует query билдеры.
На рисунке \ref{img:AccessToDB} представлена UML-диаграмма компонента доступа к данным.
\begin{figure}[H]
	\centering
	\includegraphics[scale=0.35]{AccessToDB.png}
	\caption{Компонент доступа к данным.}
	\label{img:AccessToDB}
\end{figure}
\subsubsection{Компонент бизнес-логики}
На рисунке \ref{img:Controllers} представлена UML-диаграмма компонента бизнес-логики.
\begin{figure}[H]
	\centering
	\includegraphics[scale=1]{Controllers.png}
	\caption{Компонент бизнес-логики.}
	\label{img:Controllers}
\end{figure}
\subsection{Интерфейс приложения}
На рисунках ниже показан пользовательский интерфейс.
\begin{figure}[H]
	\centering
	\includegraphics[scale=0.75]{admin.jpg}
	\caption{Вкладка админа.}
	\label{img:analytic}
\end{figure}
\begin{figure}[H]
	\centering
	\includegraphics[scale=0.75]{guest.jpg}
	\caption{Общедоступная вкладка.}
	\label{img:manager}
\end{figure}

\subsection{Вывод}
В данном разделе были выбраны средства реализации поставленной задачи, создана база данных, разработано приложение.
\newpage
\section*{Заключение}
\addcontentsline{toc}{section}{Заключение}
В процессе выполнения курсовой работы задание было формализовано, был проведен анализ предметной области, были выбраны подходящие инструменты для решения задачи и был спроектирован и реализован программный комплекс. \\
\indent Цель курсовой работы достигнута.

В процессе разработки была заложена возможность масштабирования системы. В качестве дальнейшего развития можно предложить введение системы в эксплуатацию, добавление возможности управлять сенсором через приложение, доработка UI приложения и логики добавления новых запросов.

\clearpage
%СПИСОК ЛИТЕРАТУРЫ
\begin{thebibliography}{9}
	\addcontentsline{toc}{section}{Литература}
	\bibitem{netflow} Introduction to Cisco IOS NetFlow [Электронный ресурс] URL: https://www.cisco.com/c/en/us/products/collateral/ios-nx-os-software/ios-netflow/prod\_white\_paper0900aecd80406232.html (дата обращения: 09.06.2021).
	\bibitem{wireshark} Wireshark [Электронный ресурс] URL: https://www.wireshark.org/ (дата обращения: 09.06.2021).
	\bibitem{tcpdump} Man page of tcpdump [Электронный ресурс] URL: https://www.tcpdump.org/manpages/tcpdump.1.html (дата обращения: 09.06.2021).
	\bibitem{elastic} Elasticksearch as NoSQL [Электронный ресурс] URL:  https://www.elastic.co/blog/found-elasticsearch-as-nosql (дата обращения: 09.06.2021).
	\bibitem{clickhouse} ClickHouse : Введение [Электронный ресурс] URL: https://clickhouse.tech/docs/ru/introduction/distinctive-features/ (дата обращения: 09.06.2021).
	\bibitem{clickhouse-kafka} ClickHouse : Kafka [Электронный ресурс] URL: https://clickhouse.tech/docs/en/engines/table-engines/integrations/kafka/ (дата обращения: 09.06.2021).
	\bibitem{clickhouse-elastic} ClickHouse vs Elasticsearch [Электронный ресурс] URL: https://altinity.com/faqs/clickhouse-and-elasticsearch-faqs (дата обращения: 09.06.2021).
	\bibitem{sharp} Документация по C\# [Электронный ресурс] URL: https://docs.microsoft.com/ru-ru/dotnet/csharp/ (дата обращения: 09.06.2021).
	\bibitem{vs} Документация по семейству продуктов Visual Studio [Электронный ресурс] URL: https://docs.microsoft.com/ru-ru/visualstudio/?view=vs-2019 (дата обращения: 09.06.2021).
\end{thebibliography}

 \clearpage
 {\centering\textbf{Приложение А.} \par}
 {\centering Создание таблиц базы данных. \par}
 \addcontentsline{toc}{section}{Приложение А. Создание таблиц базы данных.}
\begin{lstlisting}[label={lst:appA}, language=SQL]

CREATE TABLE IF NOT EXISTS flows
(
    TimeReceived UInt64,
    TimeFlowStart UInt64,
    SequenceNum UInt32,
    SamplingRate UInt64,
    SamplerAddress FixedString(16),
    SrcAddr FixedString(16),
    DstAddr FixedString(16),
    SrcAS UInt32,
    DstAS UInt32,
    EType UInt32,
    Proto UInt32,
    SrcPort UInt32,
    DstPort UInt32,
    Bytes UInt64,
    Packets UInt64
)
ENGINE = Kafka
SETTINGS kafka_broker_list = '192.168.1.53:9092',
 kafka_topic_list = 'flows',
 kafka_group_name = 'clickhouse',
 kafka_format = 'Protobuf',
 kafka_schema = './flow.proto:FlowMessage';
 
CREATE TABLE IF NOT EXISTS flows_raw
(
    Date Date,
    TimeReceived DateTime,
    TimeFlowStart DateTime,
    SequenceNum UInt32,
    SamplingRate UInt64,
    SamplerAddress FixedString(16),
    SrcAddr FixedString(16),
    DstAddr FixedString(16),
    SrcAS UInt32,
    DstAS UInt32,
    EType UInt32,
    Proto UInt32,
    SrcPort UInt32,
    DstPort UInt32,
    Bytes UInt64,
    Packets UInt64
)
ENGINE = MergeTree
PARTITION BY Date
ORDER BY TimeReceived
SETTINGS index_granularity = 8192;
   
CREATE MATERIALIZED VIEW IF NOT EXISTS default.flows_raw_view TO default.flows_raw
(
    `Date` Date,
    `TimeReceived` UInt64,
    `TimeFlowStart` UInt64,
    `SequenceNum` UInt32,
    `SamplingRate` UInt64,
    `SamplerAddress` FixedString(16),
    `SrcAddr` FixedString(16),
    `DstAddr` FixedString(16),
    `SrcAS` UInt32,
    `DstAS` UInt32,
    `EType` UInt32,
    `Proto` UInt32,
    `SrcPort` UInt32,
    `DstPort` UInt32,
    `Bytes` UInt64,
    `Packets` UInt64
) AS
SELECT
    toDate(TimeReceived) AS Date, *
FROM default.flows;
    
    
CREATE TABLE IF NOT EXISTS data_sources (
                        Ip String,
                        OwnerUUID UUID,
                        Type Int16
                        )
                        ENGINE=MergeTree()
                        ORDER BY (Ip);
                        
CREATE TABLE IF NOT EXISTS data_source_types (
                        Type Int16,
                        Info String
                        )
                        ENGINE=MergeTree()
                        ORDER BY (Type);
                       
   CREATE TABLE IF NOT EXISTS data_destinations (
                        Ip String,
                        Type Int16
                        )
                        ENGINE=MergeTree()
                        ORDER BY (Ip);
                       
   CREATE TABLE IF NOT EXISTS data_destination_types (
                        Type Int16,
                        Info String
                        )
                        ENGINE=MergeTree()
                        ORDER BY (Type);
                       
   CREATE TABLE IF NOT EXISTS user_info (
                        Id UUID,
                        Name String,
                        Post String
                        )
                        ENGINE=MergeTree()
                        ORDER BY (Id);
\end{lstlisting}
 \newpage
\addcontentsline{toc}{section}{Приложение Б. Презентация.}
 {\centering\textbf{Приложение Б. Презентация} \par}
\begin{figure}[H]
	\centering
	\includegraphics[scale=0.35]{pr1.jpg}
\end{figure}
\begin{figure}[H]
	\centering
	\includegraphics[scale=0.35]{pr2.jpg}
\end{figure}
\begin{figure}[H]
	\centering
	\includegraphics[scale=0.35]{pr3.jpg}
\end{figure}
\begin{figure}[H]
	\centering
	\includegraphics[scale=0.35]{pr4.jpg}
\end{figure}
\begin{figure}[H]
	\centering
	\includegraphics[scale=0.35]{pr5.jpg}
\end{figure}
\begin{figure}[H]
	\centering
	\includegraphics[scale=0.35]{pr6.jpg}
\end{figure}
\begin{figure}[H]
	\centering
	\includegraphics[scale=0.35]{pr7.jpg}
\end{figure}
\begin{figure}[H]
	\centering
	\includegraphics[scale=0.35]{pr8.jpg}
\end{figure}
\begin{figure}[H]
	\centering
	\includegraphics[scale=0.35]{pr9.jpg}
\end{figure}
\begin{figure}[H]
	\centering
	\includegraphics[scale=0.35]{pr10.jpg}
\end{figure}
\end{document}